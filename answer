#!/usr/bin/env python3

from __future__ import unicode_literals, print_function
from spacy.lang.en import English # updatedimport os
import spacy
import sys
import string
import preprocess as st

from wh_ask import WhQuestionGenerator
from binary_ask import BinaryQuestionGenerator
from question_runner import QuestionRunner

sentences= English()
nlp = spacy.load('en_core_web_md')
stopwords = spacy.lang.en.stop_words.STOP_WORDS
sentences.add_pipe(sentences.create_pipe('sentencizer')) # updated

class answer_question:
    def __init__(self, text_file, question_file):

        with open(text_file, 'r') as file:
            text = file.read()

        # Instantiate our preprocessor and get the processed doc
        preprocesser = st.Preprocessor(text)
        processed_doc = preprocesser.doc

        # get the avg coref len of the doc (to pass to rankers)
        avg_coref_len = preprocesser.avg_coref_len

        # Instantiate our question generators
        wh_gen = WhQuestionGenerator()
        binary_gen = BinaryQuestionGenerator()

        # Instantiate our question runner
        question_generator = QuestionRunner(processed_doc,
                                            avg_coref_len,
                                            wh_gen,
                                            binary_gen)

        # generate and save our questions
        question_generator.generate_questions(1000, should_print=False)
        self.our_questions = question_generator.questions

        doc = sentences(text)
        self.sentences = [sent.string.strip() for sent in doc.sents]

        with open(question_file, 'r') as q_file:
            self.q_list = q_file.read().split('\n')

    def find_best_matches_vectorized(self, question):

        q_type = self.classify(question)

        question = nlp(question)
        question = ' '.join([token.text for token in question if not token.is_stop])
        print('STOPWORDS REMOVED: ', question)

        # generate (similarity, question) list for each question
        candidates = []
        for question in self.our_questions:
            sent = question.q_string
            q_class = question.q_class
            correct_answer = question.q_answer
            og_candidate = nlp(str(sent))
            candidate = ' '.join([token.text for token in og_candidate if not token.is_stop])
            candidate = nlp(candidate)
            score = nlp(sent).similarity(candidate)
            if not q_type and correct_answer:
                candidates.append((score, og_candidate, correct_answer))
            elif q_class == q_type and correct_answer:
                candidates.append((score, og_candidate, correct_answer))

        similarity_dict = dict()
        if not candidates:
            for sent in self.sentences:
                similarity_dict[sent] = nlp(question).similarity(nlp(sent))
            best_sentence = max(similarity_dict, key=similarity_dict.get)

            return self.answer_no_match(question, best_sentence, q_type)

        
        # return most similar candidate
        # print(sorted(candidates, key=lambda x: x[0], reverse=True)[:3])
        most_similar = max(candidates, key=lambda x: x[0])

        if most_similar[0] > 0.88:
            return most_similar[2]
        return None

    def classify(self, question):
        types = ['WHO', 'WHAT', 'WHERE', 'WHEN', 'WHY', 'HOW', 'WHICH', 'BINARY']
        for t in types:
            if t in question.upper():
                return t
        return None

    def make_question_set(self, question):
        q = nlp(question)
        q_words = set(['WHO', 'WHAT', 'WHERE', 'WHEN', 'WHY', 'HOW', 'WHICH', '?'])
        question_vector = set()
        for word in q:
            if word.text not in q_words:
                question_vector.add(word.text.upper())
        return question_vector

    def find_best_matches(self, question_vector):
        matches = dict()
        for sentence in self.sentences:
            match_count = 0
            sentence = nlp(sentence)
            for word in sentence:
                if word.text.upper() in question_vector:
                    match_count += 1
            match_percent = float(match_count / len(sentence))
            matches[sentence.text] = match_percent
        return max(matches, key = matches.get)

    def answer_no_match(self, question, best_sentence, q_type):
        if q_type == 'WHO' or q_type == 'WHAT':
            sentence_doc = nlp(best_sentence)
            question_doc = nlp(question)
            removed_matches = []
            for token in sentence_doc:
                if token.text not in question:
                    removed_matches.append(token)
            for token in removed_matches:
                if token.dep_ == question_doc[0].dep_ or token.dep_ == 'nsubj':
                    return token.text
            if removed_matches:
                return removed_matches[0].text
            else:
                return best_sentence
        if q_type == 'WHERE':
            locations = ['LOC', 'GPE', 'ORG', 'FAC']
            sentence_doc = nlp(best_sentence)
            question_doc = nlp(question)
            removed_matches = []
            for token in sentence_doc:
                if token.text not in question:
                    removed_matches.append(token)
            for token in removed_matches:
                if token.dep_ == question_doc[0].dep_ or token.ent_type_ in locations:
                    return token.text
            if removed_matches:
                return removed_matches[0].text
            else:
                return best_sentence
        if q_type == 'WHEN':
            times = ['DATE', 'TIME', 'CARDINAL', 'ORDINAL']
            sentence_doc = nlp(best_sentence)
            question_doc = nlp(question)
            removed_matches = []
            for token in sentence_doc:
                if token.text not in question:
                    removed_matches.append(token)
            for token in removed_matches:
                if token.dep_ == question_doc[0].dep_ or token.ent_type_ in times:
                    return token.text
            if removed_matches:
                return removed_matches[0].text
            else:
                return best_sentence
        if q_type == 'WHY':
            words = ['BECAUSE', 'SINCE', 'SO']
            sentence_doc = nlp(best_sentence)
            question_doc = nlp(question)
            for i in range(len(sentence_doc)):
                print(sentence_doc[i].text, sentence_doc[i].pos_)
                if sentence_doc[i].text.upper() in words:
                    return ' '.join([token.text for token in sentence_doc[i + 1:]])
            return best_sentence
        if q_type == 'BINARY':
            sentence_doc = nlp(best_sentence)
            question_doc = nlp(question)
            for token in sentence_doc:
                if token.dep_ == 'neg':
                    return 'No'
            return 'Yes'
        return best_sentence


answer_question = answer_question(sys.argv[1], sys.argv[2])

for question in answer_question.q_list:
    print('###### QUESTION ######')

    match = answer_question.find_best_matches_vectorized(question)
    print(match)




